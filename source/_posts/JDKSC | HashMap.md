Hash table based implementation of the Map interface. This implementation provides all of the optional map eperations, and permits null values and the null key. (The HashMap class is roughly equivalent to Hashtable, except that it is unsynchronized and permits nulls.)  
This class makes no guarantees as to the order of the map;in particular, it does not guarantee that the order will remain constant over time.
> guarantees particular constant unsynchronized permits except equivalent roughly eperations 

This implementation provides constant-time performance for the basic operations(get and put), assuming the hash function disperses the elements propperly among the buckets. Iteration over collection views requires time proportional to the "capacity" of the HashMap instance (the number of buckets) plus its size(the number of key-value mappings). Thus, it is very important not to set the initial capacity too high (or the load factor too low) if iteration performance is important.

An instance of HashMap has two parameters that affect its performance:
initial capacity and load factor. The capacity is the number of buckets in the hash table, and the initial cpaacity is simply the capacity at the time the hash table is created. The load factor is a measure of how full the hash table is allowed to get before its capacity if automatically increased. When the number of entries in the hash table exceeds the product of load factor and the current capacity, the hash table is rehashed (that is, internal data structures are rebuilt) so that the hash table has approximately twice the number of buckets.

As a general rule, the default load factor(.75) offers a good tradeoff between time and space costs. Higher values decrease the space overhead but increase the lookup cost (reflected in most of the opreations of the HashMap class, including get and put). The expected number of entries in the map and its load fector should be taken into account when setting its initial capacity, so as to minimize the number of rehash operations. If the initial capacity is greater than the maximum nubmer of entries divided by the load factor, no rehash operations will ever occur.

If many mappings are to be stored in a HashMap instance, creating it with a suffciently large capacity will allow the mappings to be stored more efficiently than letting it perform automatic rehashing as needed to grow the table. Note that using many keys with the same hashCode() is sure way to slow down performance of any hash table. To amiliorate impact, when keys are Comparable, this class may use comparison order among keys to help break ties.

Note that this implementation is not sunchronized, if multiple thread access a hash map concurrently, and at least one of the threads modifies the map structurally, it must be sunchronized externally. (A structural modification is any operation that adds or delete on or more mappings; merely changing hte value associated with a key taht adds or deletes on or more mapping; merely changing the value associated with a key that an instance already contains is not a structural modification.) This is typically accomplished by synchronizing on some object that naturally encapsulates the map. If no such object exists, the map should be "wrapped" using the Collections.sunchroniedMap method, Thsi is best done at creation time, to prevent accidental unsynchronized access to the map: 
` Map m = Collections.synchroniedMap(new HashMap(...));`
The iterators returned by all of this class's "collection view methods" are fail-fast: if the map is structurally modified at any time after the iterator si created , in any way except through the iterator's own remove method, the iterator will throw a ConcurrentModificationException. Thus, inthe face of concurrent modification, the iterator fails quickly and cleanly, rather than risking arbitrary, non-deterministic behavior at an undetermined time in the future.

Note that the fail-fast behavior of an iterator cannot be guaranteed as it is , generally speaking, impossible to make any hard guarantees in the presence of unsynchronized concurrent modification. Fail-fast iterators throw COncurrentModificationException on a best-effort basis. Therefore, it would be wrong to write a programmer that depended on this exception for its correctness: the fail-fast behavior of iterators should be used only yo detect bugs.

Implementation notes:
This map usually acts as binned (bucketed) hash table, but when bins get too large, they are tansformed into bins of TreeNodes, each structured similarly to these in java.util.TreeMap. Most methods try to use normal bins, but relay to TreeMap. Most methods try to use normal bins, but relay to TreeNode methods when applicable(simply by checking instanceof a node). Bins of TreeNodes may be traversed and used like any others, but additionally support faster lookup when overpopulated. However, since the vast majority of bins in normal use are not overpopulated, checking for existence of tree bins may be delayed in the course of table methods.

Tree bins(i.e., bins whose elements are all TreeNodes) are ordered primarily be hashCode, but in the case of ties, if two elements are of the same "class C implements Comparable<C>", type then their comparTo method is used for ordering.(We conservatively check generic types via reflection to validate this -- see method comparaCalassFor). The added complexity or tree bins is worthwhile in providing worst-case 0(log n) operations when keys either have distinct hashed or are orderable, Thus, performance degrades gracefully under accidental or malicioous usages in which hashCode() methods return values that are poorly distributed.